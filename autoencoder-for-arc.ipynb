{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import combinations,permutations\n",
    "from sklearn.tree import *\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import random\n",
    "from math import floor\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset, sampler\n",
    "from matplotlib import pyplot as plt\n",
    "from albumentations import (GaussianBlur,RandomCrop,MedianBlur,ElasticTransform,Flip,HorizontalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\n",
    "from albumentations.pytorch.transforms import ToTensor\n",
    "import cv2\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from torchvision import datasets,models,transforms\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/kaggle/input/abstraction-and-reasoning-challenge\")\n",
    "train_path = data_path/'training'\n",
    "test_path = data_path/'test'\n",
    "evaluation_path = data_path/'evaluation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from os.path import join as path_join\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    tasks = pd.Series()\n",
    "    for file_path in os.listdir(path):\n",
    "        task_file = path_join(path, file_path)\n",
    "\n",
    "        with open(task_file, 'r') as f:\n",
    "            task = json.load(f)\n",
    "\n",
    "        tasks[file_path[:-5]] = task\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0b148d64    {'train': [{'input': [[8, 8, 8, 8, 8, 0, 8, 8,...\n",
       "54d9e175    {'train': [{'input': [[0, 0, 0, 5, 0, 0, 0, 5,...\n",
       "a8c38be5    {'train': [{'input': [[5, 5, 5, 0, 0, 0, 0, 0,...\n",
       "ce9e57f2    {'train': [{'input': [[0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "57aa92db    {'train': [{'input': [[0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tasks = load_data('../input/abstraction-and-reasoning-challenge/training/')\n",
    "evaluation_tasks = load_data('../input/abstraction-and-reasoning-challenge/evaluation/')\n",
    "test_tasks = load_data('../input/abstraction-and-reasoning-challenge/test/')\n",
    "train_tasks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting functions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "def plot_task(task,j=0,k=0):\n",
    "    \"\"\"\n",
    "    Plots the first train and test pairs of a specified task,\n",
    "    using same color scheme as the ARC app\n",
    "    \"\"\"\n",
    "    cmap = colors.ListedColormap(\n",
    "        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "    norm = colors.Normalize(vmin=0, vmax=9)\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(15,15))\n",
    "    axs[0].imshow(task['train'][j]['input'], cmap=cmap, norm=norm)\n",
    "    axs[0].axis('off')\n",
    "    axs[0].set_title('Train Input')\n",
    "    axs[1].imshow(task['train'][j]['output'], cmap=cmap, norm=norm)\n",
    "    axs[1].axis('off')\n",
    "    axs[1].set_title('Train Output')\n",
    "    axs[2].imshow(task['test'][k]['input'], cmap=cmap, norm=norm)\n",
    "    axs[2].axis('off')\n",
    "    axs[2].set_title('Test Input')\n",
    "    axs[3].imshow(task['test'][k]['output'], cmap=cmap, norm=norm)\n",
    "    axs[3].axis('off')\n",
    "    axs[3].set_title('Test Output')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "    \"\"\"\n",
    "    Plots the first train and test pairs of a specified task,\n",
    "    using same color scheme as the ARC app\n",
    "    \"\"\"\n",
    "    cmap = colors.ListedColormap(\n",
    "        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "    norm = colors.Normalize(vmin=0, vmax=9)\n",
    "    m = len(images)\n",
    "    fig, axs = plt.subplots(1, m, figsize=(15,15))\n",
    "    for i in range(m):\n",
    "        axs[i].imshow(images[i], cmap=cmap, norm=norm)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title('Image' + str(i))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "DSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fund_unit:\n",
    "    \n",
    "    def __init__(self,colour,position,ambient = -1):\n",
    "        self.colour = colour\n",
    "        self.position = position #list of places\n",
    "        l1 = [x[0] for x in position]\n",
    "        l2 = [x[1] for x in position]\n",
    "        a = min(l1)\n",
    "        corners = get_corners(position)\n",
    "        self.top_right = corners['top_right']\n",
    "        self.top_left = corners['top_left']\n",
    "        self.bottom_left = corners['bottom_left']\n",
    "        self.bottom_right = corners['bottom_right']\n",
    "        self.colour = colour\n",
    "        self.ambient = ambient\n",
    "        self.right = corners['right']\n",
    "        self.left = corners['left']\n",
    "        self.bottom = corners['bottom']\n",
    "        self.top = corners['top']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create(colour,position):\n",
    "    unit = fund_unit(colour,position)\n",
    "    return(unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Attribute functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#units is a list\n",
    "def get_colour_dict(units):\n",
    "    colours = {}\n",
    "    for j in range(10):\n",
    "        colours[j] = []\n",
    "        for unit in units:\n",
    "            if unit.colour == j:\n",
    "                colours[j].append(unit)\n",
    "        colours[j].sort(key = lambda unit: (unit.top_left[0],unit.top_left[1]))\n",
    "    return(colours)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corners(position):\n",
    "    l1 = [x[0] for x in position]\n",
    "    l2 = [x[1] for x in position]\n",
    "    a = min(l1)\n",
    "    l3 = []\n",
    "    for x in position:\n",
    "        if x[0] == a:\n",
    "            l3.append(x[1])\n",
    "    b = min(l3)\n",
    "    c = max(l3)\n",
    "    corners = {'top_left' : np.array([a,b]),'top_right' : np.array([a,c])}\n",
    "    a = max(l1)\n",
    "    for x in position:\n",
    "        if x[0] == a:\n",
    "            l3.append(x[1])\n",
    "    b = min(l3)\n",
    "    c = max(l3)\n",
    "    corners['bottom_left'] = np.array([a,b])\n",
    "    corners['bottom_right'] = np.array([a,c])\n",
    "    # get the coordinates of the top cell\n",
    "    a = min(l1)\n",
    "    l3 = []\n",
    "    for x in position:\n",
    "        if x[0] == a:\n",
    "            l3.append(x[1])\n",
    "    l3.sort()        \n",
    "    if len(l3)%2 == 1:\n",
    "        m = (len(l3)-1)//2\n",
    "    else:\n",
    "        m = len(l3)//2\n",
    "    corners['top'] = np.array([a,l3[m]])\n",
    "    #coordinates of the bottom cell\n",
    "    a = max(l1)\n",
    "    l3 = []\n",
    "    for x in position:\n",
    "        if x[0] == a:\n",
    "            l3.append(x[1])\n",
    "    l3.sort()        \n",
    "    if len(l3)%2 == 1:\n",
    "        m = (len(l3)-1)//2\n",
    "    else:\n",
    "        m = len(l3)//2\n",
    "    corners['bottom'] = np.array([a,l3[m]])    \n",
    "    #coordinates of the left cell\n",
    "    a = min(l2)\n",
    "    l3 = []\n",
    "    for x in position:\n",
    "        if x[1] == a:\n",
    "            l3.append(x[0])\n",
    "    l3.sort()        \n",
    "    if len(l3)%2 == 1:\n",
    "        m = (len(l3)-1)//2\n",
    "    else:\n",
    "        m = len(l3)//2\n",
    "    corners['left'] = np.array([l3[m],a])\n",
    "    #coordinates of the right cell \n",
    "    a = max(l2)\n",
    "    l3 = []\n",
    "    for x in position:\n",
    "        if x[1] == a:\n",
    "            l3.append(x[0])\n",
    "    l3.sort()        \n",
    "    if len(l3)%2 == 1:\n",
    "        m = (len(l3)-1)//2\n",
    "    else:\n",
    "        m = len(l3)//2\n",
    "    corners['right'] = np.array([l3[m],a])\n",
    "    return(corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_list(units):\n",
    "    units.sort(key = lambda u : len(u.position))\n",
    "    return(units)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns chunks of unit1 which are copies of unit2 after moving it. \n",
    "def pattern_matching(unit1,unit2,with_colour = False):\n",
    "    if with_colour and not unit1.colour == unit2.colour:\n",
    "        return([])\n",
    "    else:\n",
    "        l = []\n",
    "        matches = []\n",
    "        y = unit2.position[0]\n",
    "        for x in unit1.position:\n",
    "            l.append(x-y)\n",
    "        s1 = [(a[0],a[1]) for a in unit1.position]        \n",
    "        s1 = set(s1)\n",
    "        for z in l:\n",
    "            p2 = [y + z for y in unit2.position]\n",
    "            p2 = [(a[0],a[1]) for a in p2]\n",
    "            p2 = set(p2)\n",
    "            if p2.issubset(s1):\n",
    "                p2 = list(p2)\n",
    "                p2 = [np.array([a[0],a[1]]) for a in p2]\n",
    "                matches.append([p2,z])\n",
    "        matches.sort(key = lambda a : abs(a[1][0]) + abs(a[1][1]))\n",
    "        return(matches)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorts a list of units by size\n",
    "def sort_by_size(l):\n",
    "    l.sort(key = lambda u : len(u.position))\n",
    "    return(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_position(l,base = 0):\n",
    "    if base != 3 and base !=7:\n",
    "        l.sort(key = lambda u : (give_base(u,base)[0],give_base(u,base)[1]))\n",
    "    if base == 7:\n",
    "        l.sort(key = lambda u : (give_base(u,base)[1],give_base(u,base)[0]))\n",
    "    if base == 3:\n",
    "        l.sort(key = lambda u : (-give_base(u,base)[1],give_base(u,base)[0]))\n",
    "    return(l)\n",
    "\n",
    "def give_base(unit,base):\n",
    "    d = {}\n",
    "    d[0] = unit.top_left\n",
    "    d[1] = unit.top\n",
    "    d[2] = unit.top_right\n",
    "    d[3] = unit.right\n",
    "    d[4] = unit.bottom_right\n",
    "    d[5] = unit.bottom \n",
    "    d[6] = unit.bottom_left\n",
    "    d[7] = unit.left\n",
    "    return(d[base])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Change unit in place / Get units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_colour(l,c):\n",
    "    for unit in l:\n",
    "        unit.colour = c\n",
    "    return(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_units(img,with_diag = False):\n",
    "    img = np.array(img)\n",
    "    r,c = img.shape\n",
    "    ambient = img.shape\n",
    "    E = {}\n",
    "    V = []\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            V.append((i,j))\n",
    "            E[(i,j)] = [] \n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            if i-1 >= 0 and img[i-1,j] == img[i,j]:\n",
    "                    E[(i,j)].append((i-1,j))\n",
    "            if i+1 <= r-1 and img[i+1,j] == img[i,j]:\n",
    "                E[(i,j)].append((i+1,j))\n",
    "            if j-1 >= 0 and img[i,j-1] == img[i,j]:\n",
    "                E[(i,j)].append((i,j-1))\n",
    "            if j+1 <= c-1 and img[i,j+1] == img[i,j]:\n",
    "                E[(i,j)].append((i,j+1))\n",
    "            if with_diag:    \n",
    "                if i-1 >= 0 and j-1 >= 0 and img[i-1,j-1] == img[i,j]:\n",
    "                    E[(i,j)].append((i-1,j-1))\n",
    "                if i-1 >= 0 and j+1 <= c-1 and img[i-1,j+1] == img[i,j]:\n",
    "                    E[(i,j)].append((i-1,j+1))\n",
    "                if i+1 <= r-1 and j-1 >= 0 and img[i+1,j-1] == img[i,j]:\n",
    "                    E[(i,j)].append((i+1,j-1))\n",
    "                if i+1 <= r-1 and j+1 <= c-1 and img[i+1,j+1] == img[i,j]:\n",
    "                    E[(i,j)].append((i+1,j+1))\n",
    "    parent = DFS(V,E)\n",
    "    units = []\n",
    "    for v in parent.keys():\n",
    "        if len(parent[v]) > 0:\n",
    "            temp = [np.array([x[0],x[1]]) for x in parent[v]]\n",
    "            unit = fund_unit(img[v],temp,ambient)\n",
    "            units.append(unit)\n",
    "    units.sort(key = lambda unit: (unit.top_left[0],unit.top_left[1]))        \n",
    "    return(units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offset(coordinates,a,b):\n",
    "    new_x = coordinates[0] + a\n",
    "    new_y = coordinates[1] + b\n",
    "    return(np.array([new_x,new_y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFS(V,E):\n",
    "    colour = {}\n",
    "    parent = {}\n",
    "    for v in V:\n",
    "        colour[v] = 0\n",
    "        parent[v] = []\n",
    "    for v in V:\n",
    "        if colour[v] == 0:\n",
    "            DFS_search(v,E,parent[v],colour)\n",
    "    return(parent)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFS_search(v,E,l,colour):\n",
    "    l.append(v)\n",
    "    colour[v] = 1\n",
    "    for e in E[v]:\n",
    "        if colour[e] == 0:\n",
    "            DFS_search(e,E,l,colour)\n",
    "    colour[v] = 2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f returns a list. We want it to act on every element of a list\n",
    "def do_for_list(l,f):\n",
    "    t = []\n",
    "    for x in l:\n",
    "        t = t + f(x)\n",
    "    return(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Check for contractibility and blank space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genus(unit,with_diag = False):\n",
    "    r,c = unit.ambient\n",
    "    l = boundary_img(r,c)\n",
    "    if check_belongs_to(l,unit.position):\n",
    "        is_a_boundary = True\n",
    "    else:\n",
    "        is_a_boundary = False\n",
    "    #i = 0\n",
    "    #count = 0\n",
    "    #while check_belongs_to([l[i]],unit.position):\n",
    "    #    count += 1\n",
    "    #    i += 1\n",
    "    #    if i > len(l)-1:\n",
    "    #        break\n",
    "    #if count < 2*c + 2*r - 4:\n",
    "    #    start_key = l[i]\n",
    "    #    is_a_boundary = False\n",
    "    #else:\n",
    "    #    is_a_boundary = True\n",
    "    u = fund_unit(1,unit.position,unit.ambient)\n",
    "    img = concat([u],u.ambient)\n",
    "    units = get_units(img,with_diag)\n",
    "    enclosed_area = []\n",
    "    g = 0 \n",
    "    for v in units:\n",
    "        if check_empty_intersection(l,v.position) and check_empty_intersection(v.position,unit.position):\n",
    "            g += 1\n",
    "    return(g)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_contractible(unit,with_diag = False):\n",
    "    g = get_genus(unit,with_diag)\n",
    "    if g == 0:\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_contractible(units,with_diag = False,with_background = False):\n",
    "    non_contract = []\n",
    "    units = sort_by_size(units)\n",
    "    if not with_background and units[-1] == 0:\n",
    "        units = units[:-1]\n",
    "    for u in units:\n",
    "        if not check_contractible(u,with_diag):\n",
    "            non_contract.append(u)\n",
    "    return(non_contract)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_up_to_homotopy(units):\n",
    "    t = []\n",
    "    for u in units:\n",
    "        if not check_contractible(u):\n",
    "            t.append(u)\n",
    "    return(t)        "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Check grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_identical(l):\n",
    "    u0 = l[0]\n",
    "    t = 0\n",
    "    for u in l:\n",
    "        if len(u.position) == len(u0.position):\n",
    "            p = pattern_matching(u,u0)\n",
    "            if len(p) >= 1:\n",
    "                t += 1\n",
    "    if t == len(l):\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_grid_new(img,get_diag = False):\n",
    "    img = np.array(img)\n",
    "    ambient = np.array(img).shape\n",
    "    units = sort_by_size(get_units(img,get_diag))\n",
    "    for u in units:\n",
    "        c = 0\n",
    "        v = []\n",
    "        for w in units:\n",
    "            if w != u:\n",
    "                v.append(w)\n",
    "        r = {}\n",
    "        for w in v:\n",
    "            x = w.top_left\n",
    "            if x[0] in r.keys():\n",
    "                r[x[0]].append(w)\n",
    "            else:\n",
    "                r[x[0]] = [w]\n",
    "        temp = []\n",
    "        for k in r.keys():\n",
    "            temp.append(len(r[k]))\n",
    "        if len(set(temp)) > 1:\n",
    "            c = 1 \n",
    "        for k in r.keys():\n",
    "            if not check_identical(r[k]):\n",
    "                c = 1\n",
    "        if c == 0:\n",
    "            return([u])\n",
    "    return([]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_grid(img,get_diag = False):\n",
    "    img = np.array(img)\n",
    "    ambient = np.array(img).shape\n",
    "    units = sort_by_size(get_units(img,get_diag))\n",
    "    background = units[-1]\n",
    "    u0 = units[0]\n",
    "    c = 0\n",
    "    for u in units[:-1]:\n",
    "        if len(u0.position) == len(u.position):\n",
    "            l = pattern_matching(u0,u)\n",
    "            if len(l) > 0:\n",
    "                c += 1\n",
    "    if c == len(units)-1:\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background is the unit of largest size\n",
    "\n",
    "def get_background(img,get_diag = False):\n",
    "    img = np.array(img)\n",
    "    ambient = np.array(img).shape\n",
    "    units = get_units(img,get_diag)\n",
    "    background = sort_by_size(units)[-1]\n",
    "    return(background)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## collecting units that are surrounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_actual_coord(x,y,r,c):\n",
    "    if x >= 0 and x <= r-1 and y >= 0 and y <= c-1:\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def udlr(x,r,c):\n",
    "    a,b = x[0],x[1]\n",
    "    l = []\n",
    "    x_up = [a-1,b]\n",
    "    x_down = [a+1,b]\n",
    "    x_right = [a,b+1]\n",
    "    x_left = [a,b-1]\n",
    "    t = [x_up,x_down,x_right,x_left]\n",
    "    for i in range(4):\n",
    "        if check_actual_coord(t[i][0],t[i][1],r,c):\n",
    "            l.append(np.array(t[i]))\n",
    "    return(l)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_surrounded(u1,u2):\n",
    "    r,c = u1.ambient\n",
    "    val = True\n",
    "    for x in u1.position:\n",
    "        t = udlr(x,r,c)\n",
    "        m = len(t)\n",
    "        if m < 4:\n",
    "            val = False\n",
    "        for i in range(m):\n",
    "            if not check_belongs_to([t[i]],u1.position):\n",
    "                if not check_belongs_to([t[i]],u2.position):\n",
    "                    val = False\n",
    "    return(val)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dict - surrounded, where surrounded[u] is the list of units v surrounded by u.\n",
    "\n",
    "def get_surrounded(units):\n",
    "    surrounded = {}\n",
    "    for u in units:\n",
    "        surrounded[u] = []\n",
    "        for v in units:\n",
    "            if is_surrounded(v,u):\n",
    "                surrounded[u].append(v)\n",
    "    return(surrounded)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surrounded_list(units):\n",
    "    surrounded = []\n",
    "    d = get_surrounded(units)\n",
    "    l = []\n",
    "    for k in d.keys():\n",
    "        l = l + d[k]\n",
    "    return(l)    "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Get Shapes which are contained in other shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_img(r,c):\n",
    "    l = []\n",
    "    for j in range(c):\n",
    "        l.append(np.array([0,j]))\n",
    "    for j in range(r):\n",
    "        l.append(np.array([j,c-1]))\n",
    "    for j in range(c):\n",
    "        l.append(np.array([r-1,j]))\n",
    "    for j in range(r):\n",
    "        l.append(np.array([j,0]))\n",
    "    return(l)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersection(l1,l2):\n",
    "    l11 = [(x[0],x[1]) for x in l1]\n",
    "    l22 = [(x[0],x[1]) for x in l2]\n",
    "    l = list(set(l11)&set(l22))\n",
    "    l = [np.array(x) for x in l]\n",
    "    return(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_empty_intersection(l1,l2):\n",
    "    l = get_intersection(l1,l2)\n",
    "    if len(l) > 0:\n",
    "        return(False)\n",
    "    else:\n",
    "        return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the container is not black\n",
    "\n",
    "def get_enclosed_area(unit):\n",
    "    r,c = unit.ambient\n",
    "    l = boundary_img(r,c)\n",
    "    i = 0\n",
    "    count = 0\n",
    "    while check_belongs_to([l[i]],unit.position):\n",
    "        count += 1\n",
    "        i += 1\n",
    "        if i > len(l)-1:\n",
    "            break\n",
    "    if count < 2*c + 2*r - 4:\n",
    "        start_key = l[i]\n",
    "        is_a_boundary = False\n",
    "    else:\n",
    "        is_a_boundary = True\n",
    "    u = fund_unit(1,unit.position,unit.ambient)\n",
    "    img = concat([u],u.ambient)\n",
    "    units = get_units(img)\n",
    "    enclosed_area = []\n",
    "    if is_a_boundary:\n",
    "        for v in units:\n",
    "            if check_belongs_to([v.top_left],[u.top_left]):\n",
    "                enclosed_area += v.position                \n",
    "    if len(units) > 2 and not is_a_boundary:\n",
    "        for v in units:\n",
    "            if not check_belongs_to([v.top_left],[u.top_left]) and check_empty_intersection(l,v.position):\n",
    "                enclosed_area += v.position\n",
    "    return(enclosed_area)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contained_list(units):\n",
    "    contained = []\n",
    "    enclosed_area = []\n",
    "    for u in units:\n",
    "        if u.colour != 0:\n",
    "            enclosed_area += get_enclosed_area(u)\n",
    "    for v in units:\n",
    "        if check_belongs_to(v.position,enclosed_area):\n",
    "            contained.append(v)\n",
    "    return(contained)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contained_in(units):\n",
    "    d = {}\n",
    "    l = detect_regular_non_contractible(units)\n",
    "    for u in l:\n",
    "        d[u] = []\n",
    "        x = u.top_left\n",
    "        y = u.bottom_right\n",
    "        l1 = list(range(x[0],y[0]+1))\n",
    "        l2 = list(range(x[1],y[1]+1))\n",
    "        temp = list(itertools.product(l1,l2))\n",
    "        p = []\n",
    "        for t in temp:\n",
    "            p.append(np.array([t[0],t[1]]))\n",
    "        pdiff = []    \n",
    "        for v in p:\n",
    "            r0 = 0\n",
    "            for z in u.position:\n",
    "                if v[0] == z[0] and v[1] == z[1]:\n",
    "                    r0 += 1\n",
    "            if r0 == 0:\n",
    "                pdiff.append(v)\n",
    "        udiff = fund_unit(0,pdiff,u.ambient)\n",
    "        for v in units:\n",
    "            if check_belongs_to(v.position,u.position):\n",
    "                d[u].append(v)\n",
    "    return(d)            "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Extracting simple shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_regular(unit):\n",
    "    x = unit.top_left\n",
    "    y = unit.bottom_right\n",
    "    l1 = list(range(x[0],y[0]+1))\n",
    "    l2 = list(range(x[1],y[1]+1))\n",
    "    temp = list(itertools.product(l1,l2))\n",
    "    p = []\n",
    "    for t in temp:\n",
    "        p.append(np.array([t[0],t[1]]))\n",
    "    u0 = fund_unit(0,p,unit.ambient)\n",
    "    if len(p) == len(unit.position):\n",
    "        l = pattern_matching(u0,unit)\n",
    "        if len(l) > 0:\n",
    "            if len(l1) == len(l2):\n",
    "                return('square')\n",
    "            if len(l1) == 1 and len(l2) > len(l1):\n",
    "                return('vertical line')\n",
    "            if len(l2) == 1 and len(l1) > len(l2):\n",
    "                return('horizontal line')\n",
    "            if len(l1) > len(l2):\n",
    "                return('horizontal rectangle')\n",
    "            if len(l2) > len(l1):\n",
    "                return('vertical rectangle')\n",
    "    return('-1')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regular_shapes(units):\n",
    "    d = {}\n",
    "    d['square'] = []\n",
    "    d['vertical line'] = []\n",
    "    d['horizontal line'] = []\n",
    "    d['horizontal rectangle'] = []\n",
    "    d['vertical rectangle'] = []\n",
    "    d['-1'] = []\n",
    "    for u in units:\n",
    "        d[is_regular(u)].append(u)\n",
    "    return(d)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dict whose keys are elements of the list 'units' and whose values are equivalence classes coded as integers or the list of equivalent shapes.  \n",
    "\n",
    "def shape_equivalences(units,return_lists = True,remove_background = False): \n",
    "    #img = np.array(img)\n",
    "    #ambient = np.array(img).shape\n",
    "    units = sort_by_size(units)\n",
    "    if remove_background:\n",
    "        units = units[:-1]    \n",
    "    d = {}\n",
    "    d[units[0]] = []\n",
    "    is_key = {}\n",
    "    for u in units:\n",
    "        is_key[u] = False\n",
    "    for u in units:\n",
    "        c = 0\n",
    "        for v in units:\n",
    "            if is_key[v]:\n",
    "                if len(u.position) == len(v.position):\n",
    "                    l = pattern_matching(u,v)\n",
    "                    if len(l) > 0:\n",
    "                        c += 1\n",
    "                        d[v].append(u)\n",
    "        if c == 0:\n",
    "            d[u] = [u]\n",
    "            is_key[u] = True\n",
    "    m = len(d.keys())\n",
    "    shape_equivalences = {}\n",
    "    for j,key in enumerate(d.keys()):\n",
    "        for u in d[key]:\n",
    "            shape_equivalences[u] = j\n",
    "    if return_lists:\n",
    "        return(d)\n",
    "    else:\n",
    "        return(shape_equivalences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_num(img,task):\n",
    "    m = len(task['train'])\n",
    "    for i in range(m):\n",
    "        if np.all(img == task['train'][i]['input']):\n",
    "            return(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns list of units of an image which also occur in all other images of the training set. num = -1 when img is the test image\n",
    "\n",
    "def common_shapes_across_images(img,task,img_units,num):\n",
    "    #if num == -1:\n",
    "    #    num = get_task_num(img,task)\n",
    "    m = len(task['train'])\n",
    "    all_units = []\n",
    "    task_number = {}\n",
    "    for i in range(m):\n",
    "        if i != num:\n",
    "            units = get_units(task['train'][i]['input'])\n",
    "        else:\n",
    "            units = img_units\n",
    "        for u in units:\n",
    "            task_number[u] = i\n",
    "        all_units += units\n",
    "    if num == -1:\n",
    "        units = img_units\n",
    "        all_units += img_units\n",
    "        for u in units:\n",
    "            task_number[u] = i\n",
    "    d = shape_equivalences(all_units) \n",
    "    shapes_across_images = []\n",
    "    for x in d.keys():\n",
    "        l = [task_number[y] for y in d[x]]\n",
    "        if len(set(l)) == m:\n",
    "            shapes_across_images.append(x)\n",
    "    final_list = []\n",
    "    for x in shapes_across_images:\n",
    "         for u in d[x]:\n",
    "                if task_number[u] == num:\n",
    "                    final_list.append(u)\n",
    "    return(final_list)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_equivalences_counts(units,remove_background = False):\n",
    "    d = {}\n",
    "    s = shape_equivalences(units,True,remove_background)\n",
    "    for x in s.keys():\n",
    "        m = len(s[x])\n",
    "        if m in d.keys():\n",
    "            d[m] += s[x]\n",
    "        else:\n",
    "            d[m] = s[x]\n",
    "    return(d)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if l1 is a subset of l2. Both are lists of np arrays of length 2.\n",
    "def check_belongs_to(l1,l2):\n",
    "    r = 0 \n",
    "    for z in l1:\n",
    "        for x in l2:\n",
    "            if x[0] == z[0] and x[1] == z[1]:\n",
    "                r += 1\n",
    "    if r == len(l1):\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_this_please(u,x1,x2):\n",
    "    l1 = list(range(x1[0],x2[0]+1))\n",
    "    l2 = []\n",
    "    for t in l1:\n",
    "        l2.append(np.array([t,x1[1]]))\n",
    "    if check_belongs_to(l1,u.position):\n",
    "        count = 1\n",
    "    else:\n",
    "        count = 0\n",
    "    return(count)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# selects the regular non contractible elements of units i.e. those elements of the list units whose hole is a regular object. \n",
    "\n",
    "def detect_regular_non_contractible(units):\n",
    "    #img = np.array(img)\n",
    "    #ambient = np.array(img).shape\n",
    "    units = sort_by_size(units)\n",
    "    regular_non_contractible = []\n",
    "    for u in units:\n",
    "        x = u.top_left\n",
    "        y = u.bottom_right\n",
    "        l1 = list(range(x[0],y[0]+1))\n",
    "        l2 = list(range(x[1],y[1]+1))\n",
    "        temp = list(itertools.product(l1,l2))\n",
    "        p = []\n",
    "        for t in temp:\n",
    "            p.append(np.array([t[0],t[1]]))\n",
    "        pdiff = []    \n",
    "        for v in p:\n",
    "            r0 = 0\n",
    "            for z in u.position:\n",
    "                if v[0] == z[0] and v[1] == z[1]:\n",
    "                    r0 += 1\n",
    "            if r0 == 0:\n",
    "                pdiff.append(v)\n",
    "        if len(pdiff) > 0:        \n",
    "            udiff = fund_unit(0,pdiff,u.ambient) \n",
    "            u0 = fund_unit(0,p,u.ambient)\n",
    "            s = is_regular(udiff)\n",
    "            if s != '-1':\n",
    "                count = 0\n",
    "                x1 = udiff.top_left\n",
    "                x2 = udiff.top_right\n",
    "                l1 = list(range(x1[1],x2[1]+1))\n",
    "                l2 = []\n",
    "                for t in l1:\n",
    "                    l2.append(np.array([x1[0]-1,t]))\n",
    "                if check_belongs_to(l2,u.position):\n",
    "                    count += 1\n",
    "                x1 = udiff.top_right\n",
    "                x2 = udiff.bottom_right\n",
    "                l1 = list(range(x1[0],x2[0]+1))\n",
    "                l2 = []\n",
    "                for t in l1:\n",
    "                    l2.append(np.array([t,x1[1]+1]))\n",
    "                if check_belongs_to(l2,u.position):\n",
    "                    count += 1 \n",
    "                x1 = udiff.bottom_left\n",
    "                x2 = udiff.bottom_right\n",
    "                l1 = list(range(x1[1],x2[1]+1))\n",
    "                l2 = []\n",
    "                for t in l1:\n",
    "                    l2.append(np.array([x1[0]+1,t]))\n",
    "                if check_belongs_to(l2,u.position):\n",
    "                    count += 1    \n",
    "                x1 = udiff.top_left\n",
    "                x2 = udiff.bottom_left\n",
    "                l1 = list(range(x1[0],x2[0]+1))\n",
    "                l2 = []\n",
    "                for t in l1:\n",
    "                    l2.append(np.array([t,x1[1]-1]))\n",
    "                if check_belongs_to(l2,u.position):\n",
    "                    count += 1\n",
    "                if count == 4:\n",
    "                    regular_non_contractible.append(u)\n",
    "    return(regular_non_contractible)    "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Filter by size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_size(units):\n",
    "    f = {}\n",
    "    for j in range(1,7):\n",
    "        f[j] = []\n",
    "    for u in units:\n",
    "        if len(u.position) < 6:\n",
    "            f[len(u.position)].append(u)\n",
    "        else:\n",
    "            f[6].append(u)\n",
    "    return(f)        "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Assembling image from units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(l,ambient,background = 0):\n",
    "    r,c = ambient\n",
    "    a = np.full(ambient,background)\n",
    "    for x in l:\n",
    "        for z in x.position:\n",
    "            if z[0] >= 0 and z[0] <= r-1 and z[1] >= 0 and z[1] <= c-1:\n",
    "                a[z[0],z[1]] = x.colour\n",
    "    return(a)      "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get easier sub-collection of the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_output_shape_is_same(task):\n",
    "    return all([np.array(el['input']).shape == np.array(el['output']).shape for el in task['train']])\n",
    "\n",
    "def get_equals(task_series):\n",
    "    l = []\n",
    "    for j in task_series.index:\n",
    "        if input_output_shape_is_same(task_series[j]):\n",
    "            l.append(j)\n",
    "    return(l) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_input_output_same_size = get_equals(train_tasks)\n",
    "l_input_output_same_size.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a list of np arrays to tuples\n",
    "def convert_to_tuple(t):\n",
    "    s = [(a[0],a[1]) for a in t]\n",
    "    return(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count those images where one must only colour match\n",
    "#l_colour_match_no_diag = []\n",
    "#for index in l_input_output_same_size:\n",
    "#    task = train_tasks[index]\n",
    "#    c = 0\n",
    "#    for example in task['train']:\n",
    "#        units_input = get_units(np.array(example['input']))\n",
    "#        units_output = get_units(np.array(example['output']))\n",
    "#        if len(units_input) == len(units_output):\n",
    "#            sub_count = 0\n",
    "#            for u in units_input:\n",
    "#                s1 = set(convert_to_tuple(u.position))\n",
    "#                for v in units_output:\n",
    "#                    s2 = set(convert_to_tuple(v.position))\n",
    "#                    if s1 == s2:\n",
    "#                        sub_count += 1\n",
    "#            if sub_count == len(units_input):\n",
    "#                c += 1\n",
    "#        if c == len(task['train']):        \n",
    "#            l_colour_match_no_diag.append(index) "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs a dict with the following encoding : \n",
    "# 0 --> all units\n",
    "# 1 --> non contractible objects\n",
    "# 2 --> surrounded_list\n",
    "# 3 --> contained_in list\n",
    "# 4 --> squares \n",
    "# 5 --> vertical_line (not using for additional features)\n",
    "# 5.5 --> line\n",
    "# 6 --> horizontal line (not using for additional features)\n",
    "# 7 --> horizontal rectangle (not using for additional features)\n",
    "# 7.5 --> rectangle\n",
    "# 8 --> vertical rectangle (not using for additional features)\n",
    "# 9 --> -1 (irregular shape)\n",
    "# 10 --> regular shapes (union of 14,15,16,17,18) \n",
    "# 11 --> regular non contractible units\n",
    "# 12 --> List of shapes with no doubles\n",
    "# 13 --> shapes which are doubled\n",
    "# 14 --> Shapes which are trebled\n",
    "# 15 --> Shapes that appear in all train inputs (not using for additional features)\n",
    "# 16 --> Shapes of size 1\n",
    "# 17 --> Shapes of size 2\n",
    "# 18 --> Shapes of size 3\n",
    "# 19 --> Shapes of size 4\n",
    "# 20 --> Shapes of size 5\n",
    "# 21 --> Shapes of size greater than 5\n",
    "# All negative keys are complements of the corresponding positive keys\n",
    "\n",
    "def get_lists(img,task = None,num = -1,with_diag = False):\n",
    "    list_dict = {}\n",
    "    img = np.array(img)\n",
    "    ambient = np.array(img).shape\n",
    "    units = get_units(img,with_diag)\n",
    "    list_dict[0] = units\n",
    "    #c_dict = get_colour_dict(units)\n",
    "    #for i in range(10):\n",
    "    #    list_dict[i+1] = c_dict[i]\n",
    "    #t = get_up_to_homotopy(units)\n",
    "    list_dict[1] = get_non_contractible(units,with_diag,False)\n",
    "    list_dict[2] = surrounded_list(units)\n",
    "    list_dict[3] = contained_list(units)\n",
    "    shape_d = get_regular_shapes(units)\n",
    "    list_dict[4] = shape_d['square']\n",
    "    #list_dict[5] = shape_d['vertical line']\n",
    "    #list_dict[6] = shape_d['horizontal line']\n",
    "    list_dict[5.5] = shape_d['vertical line'] + shape_d['horizontal line']\n",
    "    #list_dict[7] = shape_d['horizontal rectangle']\n",
    "    #list_dict[8] = shape_d['vertical rectangle']\n",
    "    list_dict[7.5] = shape_d['horizontal rectangle'] + shape_d['vertical rectangle']\n",
    "    list_dict[9] = shape_d['-1']\n",
    "    list_dict[10] = shape_d['square'] + shape_d['vertical line'] + shape_d['horizontal line'] + shape_d['horizontal rectangle'] + shape_d['vertical rectangle']\n",
    "    #for count,i in enumerate(range(14,21)):\n",
    "    #    d_temp = get_colour_dict(list_dict[i])\n",
    "    #    t = extract_lists_from_dict(d_temp)\n",
    "    #    for j in range(10):\n",
    "    #        list_dict[21+(count*10)+j] = t[j]\n",
    "    list_dict[11] = detect_regular_non_contractible(units)\n",
    "    shape_counts = shape_equivalences_counts(units,False)\n",
    "    for i in range(1,4):\n",
    "        if i not in shape_counts.keys():\n",
    "            shape_counts[i] = []\n",
    "    for i in range(1,4):\n",
    "        list_dict[11+i] = shape_counts[i]\n",
    "    #list_dict[15] = common_shapes_across_images(img,task,units,num)\n",
    "    f = filter_by_size(units)\n",
    "    for j in range(1,7):\n",
    "        list_dict[15+j] = f[j]\n",
    "    #list_dict = get_list_dict_complements(units,list_dict) \n",
    "    return(units,list_dict)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_number == -1 if test\n",
    "def additional_X_features(img,task = None,task_number = -1,with_diag = False):\n",
    "    img = np.array(img)\n",
    "    units,list_dict = get_lists(img,task,task_number,with_diag)\n",
    "    d = {}\n",
    "    r,c = img.shape\n",
    "    bckg = sort_by_size(units)[-1]\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            features = []\n",
    "            if bckg.colour == 0:\n",
    "                if check_belongs_to([np.array([i,j])],bckg.position):\n",
    "                    features.append(1)\n",
    "                else:\n",
    "                    features.append(0) \n",
    "            else:\n",
    "                features.append(0)\n",
    "            for key in list_dict.keys():\n",
    "                if key > 0:\n",
    "                    temp = 0\n",
    "                    if len(list_dict[key]) > 0:\n",
    "                        t = sort_by_position(list_dict[key],0)\n",
    "                        for idx,u in enumerate(t):\n",
    "                            if check_belongs_to([np.array([i,j])],u.position):\n",
    "                                temp = idx+1\n",
    "                    features.append(temp)\n",
    "            d[(i,j)] = features\n",
    "    return(d)        "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getiorc(pair):\n",
    "    inp = pair[\"input\"]\n",
    "    return pair[\"input\"],pair[\"output\"],len(inp),len(inp[0])\n",
    "    \n",
    "def getAround(i,j,inp,size=1):\n",
    "    #v = [-1,-1,-1,-1,-1,-1,-1,-1,-1]\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    v = []\n",
    "    sc = [0]\n",
    "    for q in range(size):\n",
    "        sc.append(q+1)\n",
    "        sc.append(-(q+1))\n",
    "    for idx,(x,y) in enumerate(product(sc,sc)):\n",
    "        ii = (i+x)\n",
    "        jj = (j+y)\n",
    "        v.append(-1)\n",
    "        if((0<= ii < r) and (0<= jj < c)):\n",
    "            v[idx] = (inp[ii][jj])\n",
    "    return v\n",
    "\n",
    "def getDiagonal(i,j,r,c):\n",
    "    return\n",
    "        \n",
    "    \n",
    "def getX(inp,i,j,size):\n",
    "    z = []\n",
    "    n_inp = np.array(inp)\n",
    "    z.append(i)\n",
    "    z.append(j)\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    for m in range(5):\n",
    "        z.append(i%(m+1))\n",
    "        z.append(j%(m+1))\n",
    "    z.append(i+j)\n",
    "    z.append(i*j)\n",
    "#     z.append(i%j)\n",
    "#     z.append(j%i)\n",
    "    z.append((i+1)/(j+1))\n",
    "    z.append((j+1)/(i+1))\n",
    "    z.append(r)\n",
    "    z.append(c)\n",
    "    z.append(len(np.unique(n_inp[i,:])))\n",
    "    z.append(len(np.unique(n_inp[:,j])))\n",
    "    arnd = getAround(i,j,inp,size)\n",
    "    z.append(len(np.unique(arnd)))\n",
    "    z.extend(arnd)\n",
    "    return z\n",
    "\n",
    "def getXy(inp,oup,size,features):\n",
    "    x = []\n",
    "    y = []\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            x.append(getX(inp,i,j,size)+features[(i,j)])\n",
    "            y.append(oup[i][j])\n",
    "    return x,y\n",
    "    \n",
    "def getBkgColor(task_json):\n",
    "    color_dict = defaultdict(int)\n",
    "    \n",
    "    for pair in task_json['train']:\n",
    "        inp,oup,r,c = getiorc(pair)\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                color_dict[inp[i][j]]+=1\n",
    "    color = -1\n",
    "    max_count = 0\n",
    "    for col,cnt in color_dict.items():\n",
    "        if(cnt > max_count):\n",
    "            color = col\n",
    "            max_count = cnt\n",
    "    return color\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Augmentation + Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_colors(inp,oup,bl_cols):\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    return \n",
    "\n",
    "def replace(inp,uni,perm):\n",
    "    # uni = '234' perm = ['5','7','9']\n",
    "    #print(uni,perm)\n",
    "    r_map = { int(c):int(s) for c,s in zip(uni,perm)}\n",
    "    r,c = len(inp),len(inp[0])\n",
    "    rp = np.array(inp).tolist()\n",
    "    #print(rp)\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            if(rp[i][j] in r_map):\n",
    "                rp[i][j] = r_map[rp[i][j]]\n",
    "    return rp\n",
    "            \n",
    "    \n",
    "def augment(inp,oup,bl_cols):\n",
    "    cols = \"0123456789\"\n",
    "    npr_map = [1,9,72,3024,15120,60480,181440,362880,362880]\n",
    "    uni = \"\".join([str(x) for x in np.unique(inp).tolist()])\n",
    "    for c in bl_cols:\n",
    "        cols=cols.replace(str(c),\"\")\n",
    "        uni=uni.replace(str(c),\"\")\n",
    "        \n",
    "    exp_size = len(inp)*len(inp[0])*npr_map[len(uni)]\n",
    "    \n",
    "    mod = floor(exp_size/120000)\n",
    "    mod = 1 if mod==0 else mod\n",
    "    \n",
    "    #print(exp_size,mod,len(uni))\n",
    "    result = []\n",
    "    count = 0\n",
    "    for comb in combinations(cols,len(uni)):\n",
    "        for perm in permutations(comb):\n",
    "            count+=1\n",
    "#            if(count % mod == 0):\n",
    "            result.append((replace(inp,uni,perm),replace(oup,uni,perm)))\n",
    "    return(result)\n",
    "            \n",
    "    \n",
    "\n",
    "def get_flips(inp,oup):\n",
    "    result = []\n",
    "    flip_ids = []\n",
    "    inp = np.array(inp)\n",
    "    oup = np.array(oup)\n",
    "    if (np.fliplr(inp)).shape == inp.shape:\n",
    "        result.append((np.fliplr(inp).tolist(),np.fliplr(oup).tolist()))\n",
    "        flip_ids.append(0)\n",
    "    if  (np.rot90(np.fliplr(inp),1)).shape == inp.shape:  \n",
    "        result.append((np.rot90(np.fliplr(inp),1).tolist(),np.rot90(np.fliplr(oup),1).tolist()))\n",
    "        flip_ids.append(1)\n",
    "    if  (np.rot90(np.fliplr(inp),2)).shape == inp.shape:\n",
    "        result.append((np.rot90(np.fliplr(inp),2).tolist(),np.rot90(np.fliplr(oup),2).tolist()))\n",
    "        flip_ids.append(2)\n",
    "    if  (np.rot90(np.fliplr(inp),3)).shape == inp.shape:   \n",
    "        result.append((np.rot90(np.fliplr(inp),3).tolist(),np.rot90(np.fliplr(oup),3).tolist()))\n",
    "        flip_ids.append(3)\n",
    "    if  (np.flipud(inp)).shape == inp.shape:    \n",
    "        result.append((np.flipud(inp).tolist(),np.flipud(oup).tolist()))\n",
    "        flip_ids.append(4)\n",
    "    if  (np.rot90(np.flipud(inp),1)).shape == inp.shape:    \n",
    "        result.append((np.rot90(np.flipud(inp),1).tolist(),np.rot90(np.flipud(oup),1).tolist()))\n",
    "        flip_ids.append(5)\n",
    "    if  (np.rot90(np.flipud(inp),2)).shape == inp.shape:   \n",
    "        result.append((np.rot90(np.flipud(inp),2).tolist(),np.rot90(np.flipud(oup),2).tolist()))\n",
    "        flip_ids.append(6)\n",
    "    if  (np.rot90(np.flipud(inp),3)).shape == inp.shape:   \n",
    "        result.append((np.rot90(np.flipud(inp),3).tolist(),np.rot90(np.flipud(oup),3).tolist()))\n",
    "        flip_ids.append(7)\n",
    "    if  (np.fliplr(np.flipud(inp))).shape == inp.shape:   \n",
    "        result.append((np.fliplr(np.flipud(inp)).tolist(),np.fliplr(np.flipud(oup)).tolist()))\n",
    "        flip_ids.append(8)\n",
    "    if  (np.flipud(np.fliplr(inp))).shape == inp.shape:    \n",
    "        result.append((np.flipud(np.fliplr(inp)).tolist(),np.flipud(np.fliplr(oup)).tolist()))\n",
    "        flip_ids.append(9)\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_size(task_json):\n",
    "    return 4;\n",
    "\n",
    "def get_bl_cols(task_json):\n",
    "    result = []\n",
    "    bkg_col = getBkgColor(task_json);\n",
    "    result.append(bkg_col)\n",
    "    # num_input,input_cnt,num_output,output_cnt\n",
    "    met_map = {}\n",
    "    for i in range(10):\n",
    "        met_map[i] = [0,0,0,0]\n",
    "        \n",
    "    total_ex = 0\n",
    "    for pair in task_json['train']:\n",
    "        inp,oup=pair[\"input\"],pair[\"output\"]\n",
    "        u,uc = np.unique(inp, return_counts=True)\n",
    "        inp_cnt_map = dict(zip(u,uc))\n",
    "        u,uc = np.unique(oup, return_counts=True)\n",
    "        oup_cnt_map = dict(zip(u,uc))\n",
    "        \n",
    "        for col,cnt in inp_cnt_map.items():\n",
    "            met_map[col][0] = met_map[col][0] + 1\n",
    "            met_map[col][1] = met_map[col][1] + cnt\n",
    "        for col,cnt in oup_cnt_map.items():\n",
    "            met_map[col][2] = met_map[col][2] + 1\n",
    "            met_map[col][3] = met_map[col][3] + cnt\n",
    "        total_ex+=1\n",
    "    \n",
    "    for col,met in met_map.items():\n",
    "        num_input,input_cnt,num_output,output_cnt = met\n",
    "        if(num_input == total_ex or num_output == total_ex):\n",
    "            result.append(col)\n",
    "        elif(num_input == 0 and num_output > 0):\n",
    "            result.append(col)\n",
    "    \n",
    "    result = np.unique(result).tolist()\n",
    "    if(len(result) == 10):\n",
    "        result.append(bkg_col)\n",
    "    return np.unique(result).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bl_cols = get_bl_cols(task)\n",
    "#result = augment(task['train'][0]['input'],task['train'][0]['output'],bl_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = get_flips(task['train'][0]['input'],task['train'][0]['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collecttasks(task_json,aug,bl_cols,flip=True):    \n",
    "    task_dset = []\n",
    "    for pair in task_json['train']:\n",
    "        inp,oup = pair[\"input\"],pair[\"output\"]\n",
    "        inp_big = return_big(inp)\n",
    "        oup_big = return_big(oup)\n",
    "        task_dset.append((inp_big,oup_big))\n",
    "        if(flip):\n",
    "            flips = get_flips(inp,oup)\n",
    "            #task_dset += flips\n",
    "            m = len(flips)\n",
    "            for i in range(m):\n",
    "                ainp,aoup = flips[i]\n",
    "                ainp_big = return_big(ainp)\n",
    "                aoup_big = return_big(aoup)\n",
    "                task_dset.append((ainp_big,aoup_big))\n",
    "                if(aug):\n",
    "                    augs = augment(ainp,aoup,bl_cols)\n",
    "                    for x in augs:\n",
    "                        aug0_big = return_big(x[0])\n",
    "                        aug1_big = return_big(x[1])\n",
    "                        task_dset.append((aug0_big,aug1_big))\n",
    "        else:\n",
    "            if(aug):\n",
    "                augs = augment(inp,oup,bl_cols)\n",
    "                for x in augs:\n",
    "                    aug0_big = return_big(x[0])\n",
    "                    aug1_big = return_big(x[1])\n",
    "                    task_dset.append((aug0_big,aug1_big))\n",
    "    np.random.shuffle(task_dset)       \n",
    "    task_dset = task_dset[:10000]\n",
    "    m = len(task_dset)\n",
    "    rem = 32 - m%32\n",
    "    for i in range(rem):\n",
    "        task_dset.append(task_dset[i])\n",
    "    task_dset = np.array(task_dset)        \n",
    "    return(task_dset)\n",
    "\n",
    "\n",
    "def return_big(img):\n",
    "    img = np.array(img)\n",
    "    new_img = np.zeros((30,30),int)\n",
    "    r,c = img.shape\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            new_img[i,j] = img[i,j]\n",
    "    return(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bl_cols = get_bl_cols(task)\n",
    "#dset = collecttasks(task,True,bl_cols,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dset[:,1].reshape(len(dset),-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl = provider('train',dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generic(Dataset):\n",
    "    \n",
    "    def __init__(self,task_dset):\n",
    "        self.data_x = task_dset[:,0]\n",
    "        self.data_y = task_dset[:,1]\n",
    "        #self.transform = get_transforms()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return(len(self.data_x))\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        labels = self.data_y[idx]\n",
    "        labels = np.expand_dims(labels,axis = 0)\n",
    "        #labels = labels.flatten()\n",
    "        img1 = self.data_x[idx]\n",
    "        img = np.expand_dims(img1,axis = 0)\n",
    "        #b = img.copy()\n",
    "        #c = img.copy()\n",
    "        #img = np.concatenate((img,b,c),axis = 2)\n",
    "        img = np.float32(img)\n",
    "        labels = np.float32(labels)\n",
    "        #augmented = self.transform(image = img)\n",
    "        #img = augmented['image']\n",
    "        #trfms = Compose([])\n",
    "        img = torch.tensor(img)\n",
    "        img = img.cuda()\n",
    "        labels = torch.tensor(labels)\n",
    "        labels = labels.cuda()\n",
    "        #augmented = trfms(image = labels)\n",
    "        #labels = augmented['image']\n",
    "        return(img,labels)\n",
    "    \n",
    "#def get_transforms():\n",
    "#    list_transforms = []\n",
    "#    list_transforms.extend([ToTensor(),])\n",
    "#    trfms = Compose(list_transforms)\n",
    "#    return(trfms)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provider(phase,task_dset,mean=None,std=None,batch_size = 32):\n",
    "    if phase == 'train':\n",
    "        image_dataset = generic(task_dset)\n",
    "        dataloader = DataLoader(image_dataset,batch_size = batch_size)\n",
    "    else:\n",
    "        image_dataset = denoiser(dset_df_X_eval,dset_df_Y_eval)\n",
    "        dataloader = DataLoader(image_dataset,batch_size = batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Hyperparameters\n",
    "\n",
    "epoch = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder \n",
    "# torch.nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "#                 stride=1, padding=0, dilation=1,\n",
    "#                 groups=1, bias=True)\n",
    "# batch x 1 x 28 x 28 -> batch x 512\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                        nn.Conv2d(1,32,3,padding=1),   # batch x 16 x 28 x 28\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.Conv2d(32,32,3,padding=1),   # batch x 16 x 28 x 28\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.Conv2d(32,64,3,padding=1),  # batch x 32 x 28 x 28\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.Conv2d(64,64,3,padding=1),  # batch x 32 x 28 x 28\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.MaxPool2d(2,2)   # batch x 64 x 14 x 14\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "                        nn.Conv2d(64,128,3,padding=1),  # batch x 64 x 14 x 14\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(128),\n",
    "                        nn.Conv2d(128,128,3,padding=1),  # batch x 64 x 14 x 14\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(128),\n",
    "                        nn.MaxPool2d(2,2),\n",
    "                        nn.Conv2d(128,256,3,padding=1),  # batch x 64 x 7 x 7\n",
    "                        nn.ReLU()\n",
    "        )\n",
    "        \n",
    "                \n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(batch_size, -1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder \n",
    "# torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size,\n",
    "#                          stride=1, padding=0, output_padding=0,\n",
    "#                          groups=1, bias=True)\n",
    "# output_height = (height-1)*stride + kernel_size - 2*padding + output_padding\n",
    "# batch x 512 -> batch x 1 x 28 x 28\n",
    "batch_size = 32\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                        nn.ConvTranspose2d(256,128,3,2,1,1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(128),\n",
    "                        nn.ConvTranspose2d(128,128,3,1,1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(128),\n",
    "                        nn.ConvTranspose2d(128,64,3,1,1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.ConvTranspose2d(64,64,3,1,1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "                        nn.ConvTranspose2d(64,32,3,1,1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.ConvTranspose2d(32,32,3,1,1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(32),\n",
    "                        nn.ConvTranspose2d(32,1,3,2,0,1),\n",
    "                        nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = x.view(batch_size,256,7,7)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        #out = out.view(batch_size,900)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder = Encoder().cuda()\n",
    "#decoder = decoder().cuda()\n",
    "#encoder = Encoder()\n",
    "#decoder = Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check size\n",
    "#t = decoder(encoder(batch[0]))\n",
    "#t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters = list(encoder.parameters())+ list(decoder.parameters())\n",
    "#loss_func = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(parameters, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def validation_loss(img_batch,labels_batch):\n",
    "#    m = len(img_batch)\n",
    "#    agg = 0\n",
    "#    for i in range(m):\n",
    "#        img = img_batch[i].detach().numpy()\n",
    "#        labels = labels_batch[i].detach().numpy()\n",
    "#        img = img.flatten()\n",
    "#        labels = labels.flatten()\n",
    "#        t = np.equal(img,labels)\n",
    "#        s = np.sum(t)/len(t)\n",
    "#        agg += s\n",
    "#    return(agg/m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl = provider('train',res)\n",
    "#batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(epoch):\n",
    "#    for batch in tqdm(dl):\n",
    "#        #image = batch[1].cuda()\n",
    "#        #batch[0] = batch[0].cuda()\n",
    "#        image = batch[1]\n",
    "#        batch[0] = batch[0]\n",
    "#        optimizer.zero_grad()\n",
    "#        output = encoder(batch[0])\n",
    "#        output = decoder(output)\n",
    "#        loss = loss_func(output,image)\n",
    "#        loss.backward()\n",
    "#        optimizer.step()\n",
    "#    dl_val = provider('val')\n",
    "#    val_loss = 0\n",
    "#    count = 0\n",
    "#    for batch in dl_val:\n",
    "#        count += 1\n",
    "#        actual_image = batch[1]\n",
    "#        optimizer.zero_grad()\n",
    "#        output = encoder(batch[0])\n",
    "#        output = decoder(output)\n",
    "#        #output = np.int(output)\n",
    "#        #labels = np.int(labels)\n",
    "#        val_loss += validation_loss(output,actual_image)\n",
    "#    print('Epoch : '+ str(i))\n",
    "#    print('Validation Loss : ' + str(val_loss/count))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Task Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train with batch_size = 32\n",
    "def task_solver(task):\n",
    "    bl_cols = get_bl_cols(task)\n",
    "    task_dset = collecttasks(task,True,bl_cols,True)\n",
    "    dl = provider('train',task_dset)\n",
    "    \n",
    "    encoder = Encoder().cuda()\n",
    "    decoder = Decoder().cuda()\n",
    "    \n",
    "    \n",
    "    # Set Hyperparameters\n",
    "\n",
    "    epoch = 2\n",
    "    batch_size = 32\n",
    "    learning_rate = 0.0005\n",
    "    \n",
    "    parameters = list(encoder.parameters())+ list(decoder.parameters())\n",
    "    loss_func = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(parameters, lr=learning_rate)\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        for batch in tqdm(dl):\n",
    "            #image = batch[1].cuda()\n",
    "            #batch[0] = batch[0].cuda()\n",
    "            image = batch[1]\n",
    "            optimizer.zero_grad()\n",
    "            output = encoder(batch[0])\n",
    "            output = decoder(output)\n",
    "            loss = loss_func(output,image)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    test_preds = get_test_preds(task,encoder,decoder)\n",
    "    return(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_preds(task,encoder,decoder):\n",
    "    m = len(task['test'])\n",
    "    test_preds = []\n",
    "    for i in range(m):\n",
    "        img1 = task['test'][0]['input']\n",
    "        img = return_big(img1)\n",
    "        dset = []\n",
    "        for i in range(32):\n",
    "            dset.append(img)\n",
    "        dset = list(zip(dset,dset))   \n",
    "        dset = np.array(dset)    \n",
    "        dl = provider('train',dset)\n",
    "        batch = next(iter(dl))\n",
    "        x = encoder(batch[0])\n",
    "        y = decoder(x)\n",
    "        y = y.cpu()\n",
    "        y = y[0][0].detach().numpy()\n",
    "        y = y.astype(int)\n",
    "        y = extract_actual_image(task,y)\n",
    "        test_preds.append(y)\n",
    "    return(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_test_preds(task,encoder,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int(y):\n",
    "    r,c = y.shape\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            y[i,j] = int(y[i,j])\n",
    "    return(y)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_actual_image(task,y):\n",
    "    img = task['train'][0]['input']\n",
    "    img = np.array(img)\n",
    "    r,c = img.shape\n",
    "    new_y = np.zeros((r,c))\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            new_y[i,j] = img[i,j]\n",
    "    return(new_y)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task = train_tasks[l_input_otput_same_size[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = task_solver(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_images([task['test'][0]['input'],task['test'][0]['output'],t[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img1 = task['test'][0]['input']\n",
    "#img = return_big(img1)\n",
    "#dset = []\n",
    "#for i in range(32):\n",
    "#    dset.append(img)\n",
    "#dset = list(zip(dset,dset))   \n",
    "#dset = np.array(dset)    \n",
    "#dset = np.expand_dims(dset,axis = 0)\n",
    "#dset = np.float32(dset)\n",
    "#dset = torch.tensor(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl = provider('train',dset)\n",
    "#batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = encoder(batch[0])\n",
    "#y = decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = y[0][0].detach().numpy()\n",
    "#y = int(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task_dset = collecttasks(task,True,bl_cols,True)\n",
    "#encoder = Encoder()\n",
    "#decoder = Decoder()\n",
    "#dl = provider('train',dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = (encoder(img))\n",
    "#decoder = Decoder(1)\n",
    "#y = decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch = next(iter(dl))\n",
    "#x = decoder(encoder(batch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inp_oup_dim_same(task_json):\n",
    "    return all([ len(pair[\"input\"]) == len(pair[\"output\"]) and len(pair[\"input\"][0]) == len(pair[\"output\"][0]) for pair in task_json['train']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattener(pred):\n",
    "    str_pred = str([row for row in pred])\n",
    "    str_pred = str_pred.replace(', ', '')\n",
    "    str_pred = str_pred.replace('[[', '|')\n",
    "    str_pred = str_pred.replace('][', '|')\n",
    "    str_pred = str_pred.replace(']]', '|')\n",
    "    return str_pred \n",
    "#\n",
    "#def combine_preds(tid,pm1,pm3,pm5):\n",
    "#    result = []\n",
    "#    for i in range(len(pm1)):\n",
    "#        tk_s = tid+\"_\"+str(i)\n",
    "#        str_pred = flattener(pm1[i])+\" \"+flattener(pm3[i])+\" \"+flattener(pm5[i])\n",
    "#        #print(tk_s,str_pred)\n",
    "#        result.append([tk_s,str_pred])\n",
    "#    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = test_tasks.index[0]\n",
    "#test_tasks[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumb_predict(task):\n",
    "    preds = []\n",
    "    for pair in task['test']:\n",
    "        preds.append([[0,0],[0,0]])\n",
    "    return(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:01<00:00, 11.37it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 48.62it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 44.24it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 36.98it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 55.73it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 49.79it/s]\n",
      "100%|██████████| 99/99 [00:01<00:00, 53.16it/s]\n",
      "100%|██████████| 99/99 [00:01<00:00, 54.49it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 54.65it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 56.07it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 57.31it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 55.48it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 55.17it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 55.46it/s]\n",
      "100%|██████████| 313/313 [00:05<00:00, 55.06it/s]\n",
      "100%|██████████| 313/313 [00:05<00:00, 54.19it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 55.48it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 54.89it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 54.27it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 55.60it/s]\n",
      "100%|██████████| 109/109 [00:01<00:00, 55.28it/s]\n",
      "100%|██████████| 109/109 [00:02<00:00, 51.43it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 56.24it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 55.29it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 53.75it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 55.15it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 54.73it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 55.21it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 58.06it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 57.15it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 57.77it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 55.30it/s]\n",
      "100%|██████████| 313/313 [00:06<00:00, 49.86it/s]\n",
      "100%|██████████| 313/313 [00:06<00:00, 50.62it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 56.42it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 55.82it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 56.66it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 55.90it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 56.13it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 55.52it/s]\n",
      "100%|██████████| 313/313 [00:05<00:00, 55.12it/s]\n",
      "100%|██████████| 313/313 [00:05<00:00, 53.87it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 58.02it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 56.74it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 57.98it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 56.65it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 56.96it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 56.12it/s]\n",
      "100%|██████████| 80/80 [00:01<00:00, 50.66it/s]\n",
      "100%|██████████| 80/80 [00:01<00:00, 55.13it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 55.34it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 54.51it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 56.33it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 56.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 57.39it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 55.93it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 54.96it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 56.66it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 56.52it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 58.28it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 49.99it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 56.79it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 56.39it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 55.51it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 55.83it/s]\n",
      "100%|██████████| 313/313 [00:05<00:00, 54.91it/s]\n",
      "100%|██████████| 313/313 [00:05<00:00, 54.06it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 55.71it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 54.91it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 50.31it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 57.39it/s]\n",
      "100%|██████████| 127/127 [00:02<00:00, 55.15it/s]\n",
      "100%|██████████| 127/127 [00:02<00:00, 53.16it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 52.60it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 55.43it/s]\n",
      "100%|██████████| 313/313 [00:05<00:00, 54.98it/s]\n",
      "100%|██████████| 313/313 [00:06<00:00, 50.10it/s]\n",
      "100%|██████████| 313/313 [00:05<00:00, 54.99it/s]\n",
      "100%|██████████| 313/313 [00:05<00:00, 54.14it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 57.65it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 57.37it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 56.49it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 55.95it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 57.74it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 56.79it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 57.32it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 56.33it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 55.14it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 55.36it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 47.10it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 57.41it/s]\n",
      "100%|██████████| 313/313 [00:06<00:00, 49.61it/s]\n",
      "100%|██████████| 313/313 [00:05<00:00, 52.50it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 57.28it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 53.68it/s]\n",
      "100%|██████████| 92/92 [00:01<00:00, 54.71it/s]\n",
      "100%|██████████| 92/92 [00:01<00:00, 54.97it/s]\n",
      "100%|██████████| 159/159 [00:02<00:00, 54.56it/s]\n",
      "100%|██████████| 159/159 [00:03<00:00, 52.74it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 47.38it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 40.29it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 57.14it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 56.91it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 58.22it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 57.48it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 55.75it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 55.51it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 57.82it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 56.63it/s]\n",
      "100%|██████████| 69/69 [00:01<00:00, 55.39it/s]\n",
      "100%|██████████| 69/69 [00:01<00:00, 50.61it/s]\n",
      "100%|██████████| 142/142 [00:02<00:00, 55.32it/s]\n",
      "100%|██████████| 142/142 [00:02<00:00, 55.27it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 56.17it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 55.86it/s]\n",
      "100%|██████████| 33/33 [00:00<00:00, 55.44it/s]\n",
      "100%|██████████| 33/33 [00:00<00:00, 55.54it/s]\n",
      "100%|██████████| 313/313 [00:05<00:00, 54.68it/s]\n",
      "100%|██████████| 313/313 [00:05<00:00, 54.21it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 56.80it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 56.72it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 51.42it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 51.29it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 55.58it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 55.06it/s]\n",
      "100%|██████████| 55/55 [00:01<00:00, 53.65it/s]\n",
      "100%|██████████| 55/55 [00:01<00:00, 51.90it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 39.91it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 43.44it/s]\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "start = time.time()\n",
    "result = []\n",
    "#tr = [] \n",
    "for idx in test_tasks.index:\n",
    "    now = time.time()\n",
    "    task = test_tasks[idx]\n",
    "    tk_id = idx\n",
    "    if now - start <= 7000:\n",
    "        if inp_oup_dim_same(task):\n",
    "            t = task_solver(task)\n",
    "        else:\n",
    "            t = dumb_predict(task)\n",
    "    else:\n",
    "        t = dumb_predict(task)\n",
    "       \n",
    "    for i in range(len(t)):\n",
    "            tk_s = tk_id +\"_\" + str(i)\n",
    "            temp = []\n",
    "            for row in t[i]:\n",
    "                row = list(row)\n",
    "                temp.append(row)\n",
    "            t[i] = temp \n",
    "            t[i] = np.array(t[i]).astype(int)\n",
    "            t[i] = t[i].tolist()\n",
    "            #tr.append(t[i])\n",
    "            str_pred = flattener(t[i])\n",
    "            #print(tk_s,str_pred)\n",
    "            result.append([tk_s,str_pred])    \n",
    "        \n",
    "task_ids = []\n",
    "task_preds = []\n",
    "for i in range(len(result)):\n",
    "    task_ids.append(result[i][0])\n",
    "    task_preds.append(result[i][1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def calk_score(task_test, predict):\n",
    "#    return [int(np.equal(sample['output'], pred).all()) for sample, pred in zip(task_test, predict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_pred_list(pred_map):\n",
    "#    l = list(pred_map.keys())\n",
    "#    l.sort()\n",
    "#    preds = []\n",
    "#    for i in l:\n",
    "#        preds.append(pred_map[i])\n",
    "#    return(preds)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def inp_oup_dim_same(task_json):\n",
    "#    return all([ len(pair[\"input\"]) == len(pair[\"output\"]) and len(pair[\"input\"][0]) == len(pair[\"output\"][0])\n",
    "#                for pair in task_json['train']])\n",
    "#    \n",
    "#\n",
    "#solved_task = 0\n",
    "#total_task = 0\n",
    "#task_ids = []\n",
    "#task_preds = []\n",
    "##total_score_1 = 0\n",
    "##total_score_2 = 0\n",
    "##total_score_3 = 0\n",
    "#\n",
    "#for task_path in test_path.glob(\"*.json\"):\n",
    "#    task_json = json.load(open(task_path))\n",
    "#    tk_id = str(task_path).split(\"/\")[-1].split(\".\")[0]\n",
    "#    print(tk_id)\n",
    "#    if(inp_oup_dim_same(task_json)):\n",
    "#        a_size = get_a_size(task_json)\n",
    "#        bl_cols = get_bl_cols(task_json)\n",
    "#        \n",
    "#        isflip = False\n",
    "#        X1,Y1 = gettaskxy(task_json,True,1,bl_cols,isflip)\n",
    "#        X3,Y3 = gettaskxy(task_json,True,3,bl_cols,isflip)\n",
    "#        X5,Y5 = gettaskxy(task_json,True,5,bl_cols,isflip)\n",
    "#        \n",
    "#        model_1 = BaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=100).fit(X1, Y1)\n",
    "#        model_3 = BaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=100).fit(X3, Y3)\n",
    "#        model_5 = BaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=100).fit(X5, Y5)\n",
    "#        \n",
    "#        pred_map_1 = submit_predict(task_json,model_1,1,False)\n",
    "#        pred_map_3 = submit_predict(task_json,model_3,3,False)\n",
    "#        pred_map_5 = submit_predict(task_json,model_5,5,False)\n",
    "#        \n",
    "#        #preds_1 = get_pred_list(pred_map_1)\n",
    "#        #preds_2 = get_pred_list(pred_map_3)\n",
    "#        #preds_3 = get_pred_list(pred_map_5)\n",
    "#        #\n",
    "#        #total_score_1 += calk_score(task_json['test'], preds_1)[0]\n",
    "#        #total_score_2 += calk_score(task_json['test'], preds_2)[0]\n",
    "#        #total_score_3 += calk_score(task_json['test'], preds_3)[0]\n",
    "#        \n",
    "#        for tks,str_pred in combine_preds(tk_id,pred_map_1,pred_map_3,pred_map_5):\n",
    "#            task_ids.append(tks)\n",
    "#            task_preds.append(str_pred)\n",
    "#            #print(tks,str_pred)\n",
    "#        solved_task+=1\n",
    "#        #break\n",
    "#    else:\n",
    "#        pred_map_1 = dumb_predict(task_json)\n",
    "#        pred_map_3 = dumb_predict(task_json)\n",
    "#        pred_map_5 = dumb_predict(task_json)\n",
    "#        \n",
    "#        for tks,str_pred in combine_preds(tk_id,pred_map_1,pred_map_3,pred_map_5):\n",
    "#            task_ids.append(tks)\n",
    "#            task_preds.append(str_pred)\n",
    "#            #print(tks,str_pred)\n",
    "#        \n",
    "#    total_task+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"output_id\":task_ids,'output':task_preds})\n",
    "sub_df.to_csv(\"submission.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output_id                                           1c56ad9f_0\n",
       "output       |00000000000000|00000000000000|00000000000000|...\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.iloc[5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
